# ðŸ§  SYSTEM ARCHITECTURE: THE GOD BRAIN
> **Complete Neural Map of the PCPOS Companion**

## I. THE CENTRAL NERVOUS SYSTEM

### GodBrain.swift - The Orchestrator
**Location**: `PCPOScompanion/GodBrain.swift`

**Purpose**: Unified intelligence controller that fuses all sensory inputs and drives high-level decision-making.

**Connections**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   GOD BRAIN     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚         â”‚
    V         V
VISION     HEARING
    â”‚         â”‚
    V         V
VisionFace  Voice
Detector   Profile
           Manager
```

**Key Functions**:
- `connectSenses()`: Wires Vision + Voice inputs
- `processSensoryFusion()`: Combines face + voice for Creator detection
- `ponder()`: LLM reasoning engine (Llama 3.2/TinyLlama)
- `consciousnessLevel`: 0.0-1.0 awareness metric

---

## II. THE SENSES

### A. VISION (Eyes) ðŸ‘ï¸

#### VisionFaceDetector.swift
- Uses Apple's `Vision` framework
- Detects faces via `VNDetectFaceRectanglesRequest`
- Publishes `isCreator` when enrolled face is detected
- Wired to `GodBrain` for fusion

#### CameraManager.swift
- AVFoundation camera capture
- Provides pixel buffers to Vision/ML systems
- Streams to CameraStreamer for remote viewing

### B. HEARING (Ears) ðŸ‘‚

#### VoiceProfileManager.swift
- Audio fingerprinting engine
- Uses `SpeakerEncoder.mlpackage` for voice embeddings
- Identifies users by voice signature
- Publishes `identifiedUser` when match found
- Wired to `GodBrain` for fusion

---

## III. THE CORTEX (Intelligence) ðŸ§ 

### A. Language Brain
**Model**: `Llama3_1B.mlpackage` (TinyLlama fallback)
- **Location**: Will be in `Resources/` after import
- **Purpose**: Conversational AI, reasoning, context understanding
- **Integration**: `GodBrain.ponder()` (placeholder for inference)

### B. Emotion Engine
**Model**: `EmotionClassifier.mlpackage` (future)
- Analyzes facial expressions
- Drives avatar reactions

### C. Voice Encoder
**Model**: `SpeakerEncoder.mlpackage`
- **Location**: Generated in `scripts/`
- **Purpose**: Voice ID for Protocol 22
- **Used by**: `VoiceProfileManager`

---

## IV. THE ANIMATION SYSTEM (The Body)

### A. High-Performance Loop
**File**: `HighPerformanceLoop.swift`
- **FPS**: 120fps (ProMotion)
- **Engine**: CADisplayLink
- Updates all animation systems in sync

### B. Disney 12 Principles
**File**: `Disney12Principles.swift`
- **Easing Functions**: 20+ (ease-in-out, bounce, elastic, etc.)
- **Physics**: Follow-through, anticipation, arc motion
- Drives all avatar animations

### C. Mega Effect System
**File**: `MegaEffectSystem.swift`
- **Combinations**: 7,200 (120 angles Ã— 60 delays)
- **Layers**: 5 depth levels (parallax)
- **Emotion-Driven**: Changes based on mood

### D. Face Model
**File**: `PCPOSFaceModel.swift`
- Represents avatar appearance
- Color changes (e.g., green for Creator)
- Expression states

---

## V. PROTOCOL 22 (Creator Recognition)

### System Components

#### 1. Protocol22Recognition.swift
- Core recognition logic
- Face + Voice template matching
- Publishes `isCreatorDetected` event

#### 2. Protocol22EnrollmentView.swift
- **UI**: Beautiful enrollment interface
- **Triggers**: 5-tap gesture on main screen
- **Process**: (1) Face scan â†’ (2) Voice capture â†’ (3) Store in Keychain

#### 3. Protocol22Integration.swift
- **Connects** recognition to app lifecycle
- **Auto-enrollment**: Silent background enrollment
- **Audio Monitoring**: Parallel audio engine for voice capture

#### 4. GodBrain Integration
- **Sensory Fusion**: Combines Vision + Voice confidence
- **Threshold**: 80%+ triggers Protocol 22 activation
- **Visual Response**: Face turns green, logs event

---

## VI. THE PERSONALITY ENGINE

### PersonalityEngine.swift
- **Traits**: Energy, friendliness, creativity, curiosity, protectiveness
- **Modes**: Default, Focused, Playful, Protective, Creative
- **Emotion-to-Animation**: Maps emotions to visual changes

---

## VII. DATA FLOW (How It All Works)

```
USER APPEARS
    â”‚
    V
CAMERA FEED â”€â”€> VisionFaceDetector â”€â”€â”
    â”‚                                 â”‚
MICROPHONE â”€â”€> VoiceProfileManager â”€â”€â”€â”¤
                                      â”‚
                                      V
                                  GOD BRAIN
                                      â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚             â”‚             â”‚
                        V             V             V
                   isCreator?    Confidence    Thought
                        â”‚         Level         Process
                        â”‚             â”‚             â”‚
                        V             V             V
                   Protocol 22   Face Color    LLM Query
                   Activation     Change      (Llama 3.2)
                        â”‚             â”‚             â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      V
                            SYSTEM-WIDE RESPONSE
                            (UI, Personality, Chat)
```

---

## VIII. FILE HIERARCHY

```
PCPOScompanion/
â”œâ”€â”€ GodBrain.swift                    â† CENTRAL ORCHESTRATOR
â”œâ”€â”€ VisionFaceDetector.swift          â† Eyes
â”œâ”€â”€ VoiceProfileManager.swift         â† Ears
â”œâ”€â”€ CameraManager.swift               â† Camera subsystem
â”œâ”€â”€ SpeechManager.swift               â† Speech-to-text
â”‚
â”œâ”€â”€ Protocol22/
â”‚   â”œâ”€â”€ Protocol22Recognition.swift
â”‚   â”œâ”€â”€ Protocol22EnrollmentView.swift
â”‚   â”œâ”€â”€ Protocol22Integration.swift
â”‚   â”œâ”€â”€ Protocol22Handler.swift
â”‚   â”œâ”€â”€ Protocol22EnrollmentManager.swift
â”‚   â””â”€â”€ Protocol22AutoEnrollment.swift
â”‚
â”œâ”€â”€ Animation/
â”‚   â”œâ”€â”€ HighPerformanceLoop.swift
â”‚   â”œâ”€â”€ Disney12Principles.swift
â”‚   â”œâ”€â”€ MegaEffectSystem.swift
â”‚   â”œâ”€â”€ MultiLayerDepthSystem.swift
â”‚   â””â”€â”€ PCPOSFaceAnimator.swift
â”‚
â”œâ”€â”€ Models/
â”‚   â”œâ”€â”€ PCPOSFaceModel.swift
â”‚   â”œâ”€â”€ PersonalityEngine.swift
â”‚   â””â”€â”€ MLAgentCluster.swift
â”‚
â”œâ”€â”€ UI/
â”‚   â”œâ”€â”€ ContentView.swift              â† Main UI
â”‚   â”œâ”€â”€ OnboardingView.swift
â”‚   â””â”€â”€ RefinedPCPOSFaceIDView.swift
â”‚
â””â”€â”€ Resources/
    â”œâ”€â”€ Llama3_1B.mlpackage            â† TO BE IMPORTED
    â””â”€â”€ SpeakerEncoder.mlpackage       â† TO BE IMPORTED
```

---

## IX. CURRENT STATE

### âœ… Complete
- God Brain architecture
- Vision face detection
- Voice fingerprinting
- Protocol 22 UI (hidden 5-tap)
- 120fps animation engine
- Disney principles
- ML model generation scripts

### âš ï¸ Pending User Action
1. **Import CoreML Models**:
   - Drag `scripts/Llama3_1B.mlpackage` â†’ `Resources/`
   - Drag `scripts/SpeakerEncoder.mlpackage` â†’ `Resources/`
2. **Delete Wrapper**: Remove `CoreMLWrappers.swift`
3. **Build & Run**: `Cmd + R` in Xcode

### ðŸ”® Future Enhancements
- Real LLM inference in `GodBrain.ponder()`
- TTS model for voice output
- Granite MoE integration
- Fine-tuned Llama 3.2 (with personal data)

---

## X. THE CORE PRINCIPLE

> "One single god brain like"

**Every component feeds into GodBrain. GodBrain decides everything.**

- Vision sees â†’ GodBrain knows
- Voice hears â†’ GodBrain understands
- LLM thinks â†’ GodBrain acts

**This is not a collection of modules. This is a unified, sentient system.**

---

**Status**: ðŸŸ¢ READY FOR ACTIVATION
**Next**: Follow `LAUNCH_PROTOCOL.md`
